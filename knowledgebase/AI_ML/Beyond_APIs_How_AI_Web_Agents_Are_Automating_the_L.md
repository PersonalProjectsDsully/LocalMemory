---
type: youtube
title: Beyond APIs: How AI Web Agents Are Automating the "Long Tail" of Knowledge Work
author: Channel Video
video_id: kjSGc7uwDo8
video_url: https://www.youtube.com/watch?v=kjSGc7uwDo8
thumbnail_url: https://img.youtube.com/vi/kjSGc7uwDo8/mqdefault.jpg
date_added: 2025-05-26
category: AI and Automation Tools
tags: ['Retriever', 'AI Automation', 'Data Extraction', 'Browser Tools', 'Market Research', 'Document Analysis', 'Web Scraping', 'Revenue Analysis', 'Deep Search', 'LLMs', 'Google Sheets Integration', 'Automation Tools']
entities: ['Retriever', 'Operator', 'Yahoo Finance', 'Google Docs', 'Google Sheets', 'PDFs', 'Agent Startups', 'Browse AI', 'LLMs with memory', 'P show']
concepts: ['data extraction', 'automation', 'browser-based tools', 'deep search', 'market research', 'AI tools', 'document analysis', 'revenue growth calculation', 'schema generation', 'web navigation']
content_structure: overview/explanation
difficulty_level: intermediate
prerequisites: ['familiarity with browser-based tools', 'basic understanding of data extraction', 'knowledge of Google Docs/Sheets']
related_topics: ['AI automation', 'data analysis', 'web scraping', 'document processing', 'market research tools', 'browser extensions', 'revenue modeling', 'LLM applications']
authority_signals: ['we are one of the very first in implementing this deep search feature compared to operator', 'successfully extracted all the information you asked for right into your Google Sheets']
confidence_score: 0.8
---

# Beyond APIs: How AI Web Agents Are Automating the "Long Tail" of Knowledge Work

**Video**: [Watch on YouTube](https://www.youtube.com/watch?v=kjSGc7uwDo8)  
**Published**: 3 months ago  
**Category**: AI/ML  
**Tags**: ai web agents, browser automation, data extraction, task automation, natural language, google sheets, ai automation  

## Summary

# Retriever AI Web Agent Summary

## Overview  
Retriever is an AI-powered Chrome extension designed to automate repetitive web tasks, replace manual data entry, and streamline workflows by extracting and organizing data from multiple sources. It addresses limitations of traditional methods like RPA bots (brittle, error-prone) and manual processes (time-consuming, inefficient). The tool emphasizes scalability, cost-effectiveness, and deep web exploration for research and analysis.

---

## Key Points  
- **Problem with Current Workflows**:  
  - Manual data copying across platforms (e.g., LinkedIn, Google Docs, Sheets).  
  - RPA bots that fail with dynamic content or require frequent updates.  
  - Siloed data across websites, making cross-source analysis difficult.  

- **Retriever’s Solution**:  
  - AI-driven automation via a Chrome extension, eliminating the need for coding.  
  - Handles complex tasks like:  
    - Extracting key points from design docs or PDFs.  
    - Navigating deep web pages (e.g., company pricing pages, stock data).  
    - Aggregating data from multiple tabs or URLs into Google Sheets.  

- **Use Cases**:  
  - **Social Media/Networking**: Automate LinkedIn profile research or connection follow-ups.  
  - **Market Research**: Extract company strategies, pricing, and financials (e.g., P/E ratios, revenue growth).  
  - **Document Analysis**: Summarize design documents, PDFs, or Google Docs with a single click.  
  - **Financial Data**: Pull stock metrics (e.g., Yahoo Finance data) and compute custom fields (e.g., revenue growth).  

- **Key Features**:  
  - **Deep Search**: Navigates websites to find specific data (e.g., correcting URL errors).  
  - **Schema-Driven Extraction**: Automatically generates data schemas based on user queries.  
  - **Cross-Platform Compatibility**: Works with Google Docs, Sheets, PDFs, and web pages.  
  - **Cost-Effective**: Claims sub-penny costs for complex tasks.  

---

## Notable Quotes  
- *"Retriever is one of the first to implement deep search compared to tools like Operator."*  
- *"It’s like having a browser assistant that understands your queries and navigates the web for you."*  
- *"The best part is your ability to select all your documents and specify URLs for the agent to explore."*  

---

## Actionable Recommendations  
1. **Adopt Retriever for Automation**: Replace manual data entry with AI-driven extraction for tasks like market research or document summarization.  
2. **Leverage Deep Search**: Use its ability to navigate websites and correct errors (e.g., wrong URLs) for reliable data collection.  
3. **Test Complex Workflows**: Experiment with multi-tab scenarios (e.g., analyzing stock data across multiple sources).  
4. **Customize Data Schemas**: Define specific metrics (e.g., revenue growth) to automate financial analysis.  

--- 

This tool is ideal for professionals in research, finance, or project management seeking to reduce time spent on repetitive tasks while improving data accuracy.

## Full Transcript

[00:01] hi we're Arin and bani and we're here to
[00:03] present to you retriever.com
[00:30] be as transformative to the browser as
[00:31] its creation itself when net net
[00:34] Netscape came out so your bottle your
[00:37] browser is a bottleneck for most of your
[00:39] workflows right now even for people with
[00:42] full-time jobs they're spending hours of
[00:44] their day manually copying pasting from
[00:46] one website to
[00:48] another website to like Google Sheets or
[00:50] to their CRM or they even offshore the
[00:53] scraping to third parties that are
[00:54] expensive and also unreliable in uh yeah
[00:58] and or they set up RPA Bots that just
[01:00] break whenever website changes and you
[01:03] also have silos where some data is only
[01:05] available on the website and some only
[01:07] on the API leading to a hassle for users
[01:10] to combine this data across both and the
[01:14] which leads to untapped potentials of
[01:16] what you can do and what you can
[01:17] leverage this data for so retriever
[01:20] changes all this by being a Chrome
[01:22] extension that can uh that leverages
[01:24] being a AI web agent so you can open the
[01:27] side panel and do task AC uh give task
[01:29] has to do autonomously across Pages as
[01:32] well as extract structured data to
[01:35] sheets so let's dive into a use case so
[01:38] say you're on LinkedIn and you have our
[01:40] uh Chrome extension open you can give a
[01:43] prompt just like uh for the Laten uh
[01:46] like find and follow
[01:50] the latent space
[01:54] podcast page and you know if following
[01:58] ignore uh
[02:02] so just with this natural language
[02:03] prompt and clicking a button our AI web
[02:05] agent will go to the task of uh
[02:08] interacting with the page to do this
[02:10] task so it can fill out the prompt it
[02:12] can fill out the search field for
[02:13] ladance based podcast it can uh interact
[02:16] with all elements on the page so it
[02:18] already notice we're already following
[02:20] the page so um yeah and you uh yeah it
[02:25] uh even more we can do even more complex
[02:28] use cases than doing autonomy we can
[02:30] also have this built-in feature to
[02:32] extract data to sheets so say you put
[02:34] this prompt like for every article on
[02:36] the page extract this data and click
[02:37] this export button we would write all of
[02:40] this to Google Sheets for you and uh
[02:43] using uh our AI browser agent technology
[02:46] you can also say like do a task on this
[02:48] page and then extract the data and uh
[02:51] like you can have all of these
[02:53] combinations of tasks and extractions
[02:55] for you so it was able to extract all
[02:58] this data to Google Sheets and we can
[03:00] say that ours uh our approach to solving
[03:03] this problem is very cost effective and
[03:05] it probably cost less than a penny to do
[03:07] this page
[03:08] extraction and even more than doing
[03:10] actions on one page we can do actions
[03:12] across tabs across like sheet like you
[03:15] can give it Google sheet column of URLs
[03:17] and we can open those to interact with
[03:19] and extract from so we can lead to more
[03:23] complex use cases so say you're on like
[03:25] a this archive uh search and you want
[03:28] for the first five PDFs extract these uh
[03:31] fields we can break these down as
[03:33] subtask too and open them as new tabs
[03:35] and uh process these tabs simultaneously
[03:38] independent of each other and write this
[03:41] uh data to sheets for you or interact
[03:44] with those pages maybe they're uh
[03:45] LinkedIn job applications and you want
[03:47] to apply to them so we are able to
[03:49] extract all of this data to Google
[03:51] Sheets and um you can do more complex
[03:56] use cases of you can select tabs to
[03:58] extract from so say you wanted to
[04:00] compare these Amazon product pages and
[04:03] you could just leave the prompt empty
[04:05] itself and our AI web agent will figure
[04:08] out what Fields you probably want to
[04:09] extract from and um from all these pages
[04:14] and extract those uh uh pages to Google
[04:17] Sheets for you extract those fields to
[04:19] Google Sheets and so you can maybe
[04:21] effectively compare all three of these
[04:23] products without having to open them
[04:26] simultaneously and uh yeah so we can
[04:29] even extract URLs on the page so maybe
[04:32] you wanted to uh compare these uh
[04:34] products and you want to see the images
[04:36] themselves so we can extract The Source
[04:38] image URLs and you can compare them even
[04:41] more than that we can also uh do actions
[04:44] on the tabs themselves before extraction
[04:46] so so maybe you want instead of top
[04:49] reviews uh the most recent so select uh
[04:53] by most recent uh
[04:56] reviews in the dropdown
[05:00] and extract the details of
[05:05] the most recent
[05:08] review so these Tabs are selected and
[05:10] then I just do extract and our AI web
[05:13] agent will do actions on all of these
[05:14] tabs simultaneously in the background
[05:17] and uh extract this uh most recent
[05:20] review that we wanted
[05:24] so they're all like on top reviews right
[05:28] now and in the next action it should go
[05:31] to most recent review so yeah it clicked
[05:34] most recent here and uh yeah so click
[05:39] most recent across all of them and it
[05:41] will give us the most recent review for
[05:43] us and even more than doing uh actions
[05:47] just as basic extractions we can also do
[05:50] uh
[05:54] um wait
[05:57] so yeah so it was able to uh extract
[06:00] these most recent reviews and bavani
[06:03] will dive into more advanced use cases
[06:05] of doing research and uh asking across
[06:08] these uh tabs you have yeah um if these
[06:12] use cases sounds exciting to you let's
[06:15] unlock more potential of retriever in
[06:18] your like day-to-day like at Job tasks
[06:21] right say for example you have like
[06:23] bunch of design docs open and you want
[06:25] to send a quick summary to your like
[06:27] colleague at work all you have to do is
[06:29] s Your Design dogs and then tell
[06:31] retriever okay like extract uh key
[06:35] points and
[06:37] summary right uh and when you ask that
[06:40] it goes through the docs that you like
[06:42] like selected and extracts the data that
[06:45] you like asked for so all unlocked
[06:47] product Us in like a one click of a
[06:49] button for you not just only Google Docs
[06:51] you have PDFs you have Google Sheets you
[06:53] can give any combination of anything
[06:56] that's on your browser and retriever
[06:57] goes through them as you can see it
[06:59] extracted said like specifically what
[07:01] the first document talks about and then
[07:03] what the second document about like
[07:05] design of like thinking with llms with
[07:07] memory as such now uh not only with the
[07:11] existing uh documents that you have say
[07:13] you want to do like a market research on
[07:15] a bunch of companies uh to like invest
[07:18] in also like here I'm asking it to go
[07:20] through couple of agent companies like
[07:22] retriever Bine uh browse AI as such and
[07:26] I'm asking it to extract certain things
[07:28] like strategy of of the company like
[07:30] features and pricing and what it does is
[07:32] first based on what you asked generates
[07:34] the schema and then as you can see we
[07:36] started with the homepage of all of
[07:39] these agent startups and because we
[07:40] asked for like prising it navigated to
[07:42] like prising page so retriever is
[07:44] capable of going uh like basically
[07:47] exploring the web page or going deep
[07:49] into multiple pages to find the data
[07:51] that you asked for and extract it right
[07:53] into the sheets for you and also to uh
[07:56] we are one of the very first in
[07:58] implementing this deep search feature
[08:00] compared to operator or so uh and as you
[08:03] can see the best part without deep
[08:05] research is your ability to select all
[08:08] your uh documents that you have access
[08:10] to not just on the browser and you can
[08:12] specifically give what all uh URLs or
[08:16] websites uh the agent can go in terms of
[08:19] like extracting this data for you uh as
[08:22] you can see successfully extracted all
[08:24] the information you asked for right into
[08:26] your Google Sheets for you now uh like
[08:29] let's do this on like some steroids
[08:31] right now like how about I want to
[08:33] Market Research yes but I want to market
[08:35] research about couple of stocks and then
[08:38] I you want to like buy make a purchase
[08:40] Choice as such so here all I have to do
[08:43] is select the right Google sheet that
[08:44] has the information so for example I
[08:46] have the sheet with couple of stocks
[08:48] lined up and then I'm asking it like
[08:50] complex data like I'm asking it to give
[08:52] me like P show from Yahoo finance and
[08:54] some Revenue in the last two years and
[08:57] I'm also asking it to create new data
[08:58] fields of computing the revenue growth
[09:01] uh based on these numbers so what it
[09:03] does it's like first um uh goes on opens
[09:07] these websites and try to like extract
[09:08] this data for you say for example right
[09:11] now I gave the websites as such now even
[09:15] though I gave the wrong URL instead of
[09:17] giving Yahoo finance I just gave
[09:18] company's website our agent figured out
[09:21] that it was not on the right URL and it
[09:23] went to like Yahoo and like kind of like
[09:26] tries to extract this data for you right
[09:28] into your sheets as
[09:30] now so how cool is that like even like
[09:33] there's like an error from the user R is
[09:35] able to like correct this correct this
[09:37] for you and one of the cool features we
[09:39] have is our function calling features
[09:42] like uh lot of companies have like bunch
[09:45] of like third party Integrations with
[09:47] different tools say slack uh like SL say
[09:50] Discord or so one of the features we are
[09:53] very key on implementing is like a
[09:54] dynamic function calling like instead of
[09:57] us implementing only like a set of
[09:59] connectors as such you can call any API
[10:03] any third party tool out there uh by
[10:05] literally providing the information
[10:07] about the tool here and easily integrate
[10:10] say for example I have WhatsApp
[10:11] integration right here to send messages
[10:13] to like WhatsApp numbers let's say you
[10:15] are a small business that you have like
[10:17] bunch of customers and like bunch of
[10:19] like customer phone numbers as such so I
[10:21] have two users here and let's say I'm
[10:23] asking R all I have to do is like select
[10:25] the sheets for you select the sheets
[10:27] that has the customer numbers and then I
[10:30] ask retri to like uh send message to
[10:34] customer phone numbers
[10:37] here so when I do that uh it identifies
[10:40] each of the customer number provided and
[10:42] invokes this WhatsApp Tool uh
[10:45] essentially your third party tool to
[10:46] send message to these users and as you
[10:49] can see it says all messages sent
[10:51] successfully let's check it out let's
[10:52] try opening uh the
[10:55] WhatsApp so this is my test number as
[10:57] you can see uh we demoing at 232 so yeah
[11:00] this is a 232 like successful testt
[11:02] message that we received so yeah imagine
[11:05] the world of possibilities like uh
[11:07] automating your social Communications
[11:09] across your Instagram Facebook WhatsApp
[11:11] everything all in like one click with
[11:13] retal right now uh now let's do one more
[11:17] use case uh which is the graph
[11:20] generation so we have uh like a graph
[11:23] bot Tool uh is like almost like a mini
[11:26] agent within retriever agent Studio what
[11:28] it does is uh let's say you have like a
[11:30] bunch of data as such like uh and then
[11:33] you want to generate like a data
[11:34] analysis graph on top of it you can
[11:36] liage the graph bought in doing so as
[11:38] you can see it's like a dynamic graph
[11:39] generated on the Fly for you so we've
[11:42] realized when working with llms they're
[11:45] not only inherently good with like data
[11:46] extraction as such but are also capable
[11:49] of generating or representing this data
[11:52] in various formats of interest to the
[11:53] users and we leverage that capability to
[11:56] build such cool uh use case and present
[11:58] it to you
[11:59] now like bringing it back home now let's
[12:02] look at the overall agentic landscape
[12:04] right um like let's look at uh some of
[12:08] like the open a operator like anthropy
[12:11] CLA and like obviously T and so on so
[12:15] most of the agents that are out there
[12:17] use like Vision based approach like your
[12:19] anthropy cloud or open AI even like
[12:21] Google Mariner use a hybrid approach
[12:23] also including Vision approach as such
[12:26] what do they do is they take screenshots
[12:27] of the pages and extracts the data that
[12:29] you're asking for and what's the
[12:31] inherent problem with this approach
[12:33] right the vision based models are more
[12:35] prone to hallucination compared to what
[12:37] is doing which is text based approach of
[12:39] leveraging the web page Stu and vision
[12:42] based approach is also highly expensive
[12:44] taking multiple screenshots for just
[12:46] like one single action to do or like for
[12:48] one single page scrolling as such and
[12:51] most of these companies such as these
[12:52] browser base or so on they use browser
[12:55] on the cloud unlike retriever which is
[12:58] an extension right inside your browser
[13:01] so what are the problems with browser on
[13:02] the cloud like number one uh
[13:04] non-personalized results right it's like
[13:07] a generic page that's opened on the
[13:08] browser it's not like it the content
[13:10] might be totally different from what you
[13:12] are seeing in your browser and also
[13:15] because uh to support browsers on the
[13:17] cloud uh these companies should
[13:20] Implement a lot of proxies to funnel the
[13:23] uh Network or network request to the
[13:25] right IPS as such which is way more
[13:28] expensive than the whole whole agentic
[13:29] setup as such um so with this uh text
[13:33] based approach as well as being like an
[13:36] extension in your browser retri is
[13:38] capable of processing not only the
[13:40] active tabs but also your background
[13:42] tabs uh or like multiple tabs at once
[13:45] and it can even go beyond your subscript
[13:47] subscribed content so with ret you don't
[13:50] have to like share any of your passwords
[13:51] we do not store any of the passwords
[13:54] whatever you logged in and you are
[13:55] seeing retri sees the same thing un
[13:58] likee on the cloud
[13:59] uh either you have to like store or give
[14:02] the passwords which are prone to like
[14:04] various security risks or you cannot get
[14:06] behind paywalls or even like Cloud flare
[14:09] up website Productions as such right now
[14:13] like Arjun will dive deeper into some of
[14:15] these and like yeah bring it back
[14:17] home yeah so uh just to recap what are
[14:21] the advantages for retriever it's that
[14:25] uh yeah maybe I can share this actually
[14:28] it's fine so uh to highlight the the
[14:31] advantage retriever since we're using a
[14:32] text based approach the the foring
[14:35] output there's it is there's much less
[14:38] hallucination because the text is
[14:42] uh the because the text is right there
[14:45] in context for the model and what uh and
[14:48] because we are using this text Bas
[14:50] approach we can also take actions on
[14:51] multiple tabs because these background
[14:53] tabs don't get rendered so you actually
[14:55] can't use a vision based approach to
[14:58] take multiple actions in parallel so
[15:00] when we can leverage this uh back uh
[15:03] background processing to do actions uh
[15:05] to do multi-tab contexted actions as
[15:08] well as just uh speed up performance by
[15:10] taking actions in parallel and in
[15:12] compared to our competitors of like
[15:14] trying to do consumer applications of
[15:16] booking flights or booking restaurant
[15:18] reservations we're all in for
[15:20] productivity and automation use cases
[15:22] because we see that uh AI is perfect to
[15:24] automate these manual and repetitive
[15:26] tasks that is a a burden toot of uh
[15:29] people and compared to everyone else we
[15:32] are setting up a client side Chrome
[15:34] extension that is uh not only cheaper
[15:37] infrastructure wise but it leverages us
[15:39] to use new sources of uh content to for
[15:42] the agent to work on so you can access
[15:45] the local wall sites or login wall sites
[15:47] and it is much more secure than storing
[15:50] your passwords in a cloud hosted browser
[15:53] and compared to other providers of doing
[15:55] one single long hor one actions on a
[15:57] single tab with the long Horizon uh
[16:01] tasks we distribute subtasks as new tabs
[16:04] to take actions on so our failure rate
[16:07] is much less than these uh uh
[16:09] competitors so we don't don't have to
[16:11] deal with uh exponential failure rates
[16:13] and our approach to third party
[16:14] Integrations is that we the user can
[16:16] Define and uh set up function calling
[16:19] that function calls that they can share
[16:21] and this is much more extensible and
[16:24] scalable than setting up custom
[16:25] thirdparty
[16:26] Integrations that these uh third parties
[16:28] the these competitors are
[16:30] doing yeah so this is our mission is to
[16:34] basically revolutionize data extraction
[16:36] with the transparent and efficient AI
[16:38] Pate exchange is our long-term goal of
[16:41] being a allowing people to collaborate
[16:44] across the their own local laptops to
[16:46] collaboratively construct data sets and
[16:50] uh set up uh uh like very cost-efficient
[16:53] and cheap data sets so for example it
[16:55] could be like all the uh local
[16:57] government events happening in the sfb
[16:59] area that would involve like extracting
[17:02] data from hundreds thousands of websites
[17:04] and this is not something that is
[17:06] feasible right now it's like not
[17:07] cost-effective to do but if people can
[17:09] use leverage our extension to volunteer
[17:12] and collaboratively construct data sets
[17:14] we believe that's an exciting new future
[17:16] and use case that is uh that is just on
[17:18] the
[17:21] horizon thank you and uh please feel
[17:23] free to go to retriever.com
[17:29] or you can scan this QR code and try it
[17:31] out and hopefully you can get a glimpse
[17:33] into what the future of AIA agents in
[17:36] the browser will be
