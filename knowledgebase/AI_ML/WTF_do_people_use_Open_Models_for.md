---
type: youtube
title: WTF do people use Open Models for??
author: Channel Video
video_id: wJwTlvb_TSo
video_url: https://www.youtube.com/watch?v=wJwTlvb_TSo
thumbnail_url: https://img.youtube.com/vi/wJwTlvb_TSo/mqdefault.jpg
date_added: 2025-05-26
category: Artificial Intelligence & Machine Learning
tags: ['open-source AI', 'AI applications', 'model usage analysis', 'creative AI', 'AI ethics', 'open source development', 'AI safety', 'NLP trends', 'AI agent systems', 'generative AI', 'AI in gaming', 'model versioning']
entities: ['Sam Alman', 'GPT', 'Norval Crafter', 'Wy Chat', 'Lama 2', 'Lama guard', 'Her (movie)', 'Dungeons and Dragon', 'AI Safeguard', 'Open Routers']
concepts: ['Open Source AI Models', 'AI Safety', 'Creative Writing AI', 'AI Role-Playing Companionship', 'Model Versioning', 'AI Agent Workflows', 'Open Source Development', 'AI Ethics', 'Text Generation', 'AI in Gaming']
content_structure: overview/explanation
difficulty_level: intermediate
prerequisites: ['Understanding of AI/ML fundamentals', 'Familiarity with open source ecosystems', 'Basic knowledge of AI applications']
related_topics: ['AI Ethics', 'Open Source Software Development', 'Natural Language Processing', 'AI in Creative Industries', 'Machine Learning Model Deployment', 'AI Safety Protocols', 'Generative AI Applications', 'AI Agent Systems']
authority_signals: ['we can infer usage from the model uh being used and the metadata for the requesting application', "we did and here's what we see AI usage today sorted approximately by volume and usage", "it's still the go-to model for AI Safeguard tutorials online"]
confidence_score: 0.85
---

# WTF do people use Open Models for??

**Video**: [Watch on YouTube](https://www.youtube.com/watch?v=wJwTlvb_TSo)  
**Published**: 3 months ago  
**Category**: AI/ML  
**Tags**: open models, hugging face, ai models, open source, api, model usage, deep learning  

## Summary

# Summary of "WTF do people use Open Models for??"  

## Overview  
The video explores the growing adoption of open-source AI models, their usage patterns, and the reasons behind their popularity. Hosted by Eugene, the discussion covers the rapid proliferation of models on platforms like Hugging Face, user behavior insights, and the surprising applications of open models in creative and non-traditional domains.  

---

## Key Points  
1. **Rise of Open-Source Models**  
   - Over 100,000 models are uploaded to Hugging Face monthly, with some (e.g., DC R1) surpassing commercial models like GPT-4 in performance.  
   - Pricing models like Fedus AI (free for non-commercial use) democratize access, fostering innovation.  

2. **User Behavior & Preferences**  
   - Users prioritize **model familiarity, reliability, and ease of use** over cost, leading to the continued use of older models (e.g., Lama 2) despite newer versions.  
   - **"Stickiness" of models**: Once deployed in production, users avoid updates to prevent system disruptions, even if newer models exist.  

3. **Main Use Cases**  
   - **Creative Writing**: Apps like *Norval Crafter* help authors outline novels, while fanfiction communities use AI for collaborative storytelling.  
   - **Role-Playing & Companionship**: AI-driven apps (e.g., *Wy Chat Haven*) cater to social or explicit content, despite stigma, and dominate non-coding AI traffic (30â€“40% of all usage).  
   - **Code & Productivity**: AI for coding, UI design, and task automation.  
   - **AI Agents**: Tools for automating workflows, though less common than creative or role-playing use.  

4. **Challenges & Insights**  
   - **Model Updates**: Users resist updates due to reliability concerns, even if newer models exist.  
   - **Data Inference**: Platforms like Fedus AI infer usage patterns via model metadata and customer feedback, avoiding logging sensitive data.  

---

## Quotes & Insights  
- *"Users choose models based on preference and fame, not just cost."*  
- *"Lama 2 is still the go-to model for AI Safeguard tutorials, despite newer versions."*  
- *"The role-playing and companionship segment, though stigmatized, is the number one use case for AI today."*  

---

## Actionable Items  
1. **Prioritize User Preferences**: Focus on model reliability and familiarity over cost to retain users.  
2. **Support Legacy Models**: Provide access to older versions for stability in production environments.  
3. **Monitor Diverse Use Cases**: Invest in tools for creative writing, role-playing, and niche applications to meet demand.  
4. **Balance Innovation & Stability**: Encourage updates while offering clear migration paths for users reliant on older models.  

--- 

## Conclusion  
Open-source AI models are reshaping how users interact with technology, driven by creativity, accessibility, and the enduring value of proven, stable tools. Understanding these dynamics is critical for developers and platforms aiming to meet evolving user needs.

## Full Transcript

[00:01] there is no mod the open model Warriors
[00:03] Are Climbing at the gates scaling The
[00:05] Benchmark and more importantly the
[00:06] hearts of their users in the past CH
[00:08] months more than 50,000 AI models have
[00:10] been uploaded to Hing phase per month
[00:11] and is accelera that is more than one AI
[00:14] model a minute meaning by the end of
[00:15] this talk today that's another 500
[00:17] models
[00:18] alone however not all models are equal
[00:21] the whe that crash into the room is DC
[00:22] R1 the first open source model to catch
[00:24] up and surpass GPD 4 proving that you do
[00:27] not need a billion dollars to compete
[00:28] with the big laps just a little smart
[00:29] and Prudence to catch up with over 4
[00:32] million downloads of a 685 GB model on
[00:34] huging face this past month alone this
[00:36] one model exceeds over 2.74 exabytes of
[00:39] data moving across the internet a number
[00:41] so ridiculously large that will take my
[00:42] fast 1 GB internet 690 years to transmit
[00:45] that's a lot of open models so what thef
[00:49] do people use these open models for
[00:51] us hey there I'm Eugene CEO of fedus AI
[00:55] and co-lead for the RW KV open source
[00:57] project at fedus we unlimited API
[01:00] request to over 3,700 truly open AI
[01:03] models to thousands of users with a $25
[01:06] a month flat pricing for individual with
[01:09] access to all our models including the
[01:12] famous DC R1 with larger plans for scale
[01:15] up business
[01:16] users our goal at the $25 price point is
[01:19] to provide accessibility to all truly
[01:22] open AI models with the goal of
[01:25] continuously expanding our catalog to
[01:27] eventually cover all hugging phas models
[01:31] all of which give us a unique data and
[01:34] insight in which how these open models
[01:36] are actually getting used via platform
[01:39] the how and the why and by reflection
[01:42] the open source commit as well so let's
[01:45] get the pie chart
[01:47] out let's focus on our individuals users
[01:50] first for a week in February 2025
[01:54] unsurprisingly most individuals are
[01:56] using deeps R1 followed by L tree line
[01:59] of models the mistro Nemo CH B and the
[02:03] qu line of models with everything else
[02:04] effectively Buried one important thing
[02:07] to note on this data for individual
[02:10] users is that they are not built or
[02:13] charged by tokens for feeders we are
[02:15] instead limiting the plans to one large
[02:18] model request at a time with smaller
[02:21] models typically being faster than
[02:23] larger ones there is no price difference
[02:26] for individuals here for between the
[02:28] models the end result is users choosing
[02:30] their model based on their preference
[02:31] and Vibes and perhaps the fame of the
[02:34] model instead of MML or
[02:38] price and well model classes is exciting
[02:41] from a model family wall view it is
[02:43] masking the details in the story so
[02:46] let's switch our view to models names
[02:48] instead of model class which give us A
[02:50] New
[02:51] Perspective this is where fine tuning
[02:54] fragmentation let begin where the larger
[02:56] llama and quen Pai get sliced up into
[02:58] individual models all with different
[03:00] personalities and individual use
[03:03] case however the first surprising
[03:06] Insight I would make is the stain power
[03:08] of a model once a model is used in
[03:10] production because the needs for
[03:13] business in production and users defer
[03:16] dramatically in reality most developers
[03:19] want consistency they want to only
[03:21] change their model when they choose to
[03:23] do so or up in to do so not when their
[03:25] provider decided to do an
[03:28] update nothing show this better than the
[03:30] mistro Nemo chelp because while this
[03:32] chart represents individuals are
[03:34] intentionally excluded skilled
[03:36] commercial users for Reon because when
[03:38] we add it up scale out commercial users
[03:41] which was previously excluded things
[03:43] change
[03:45] dramatically even when you switch over
[03:47] to the data by model class the dominance
[03:50] of much smaller M Nemo models which at
[03:53] this point is over 8 months old and has
[03:56] been essentially replaced by much larger
[03:57] and better model is a surprising
[04:00] observation this is contributed by the
[04:02] following factors one small models in
[04:05] general are cheaper at scale B and other
[04:08] platforms are ours in our case we
[04:11] provide access to four small models for
[04:12] the same price as one big
[04:14] model the stain power of models in
[04:16] production and tutorials is a lot more
[04:19] sticky as most people think things that
[04:23] enters production in in Enterprises
[04:25] tends to not be changed for quarters or
[04:28] or even years at a time
[04:30] you see the mro Nemo model was one of
[04:32] the early truly open source models with
[04:34] A2 licensing that surpassed even the GPD
[04:37] 3.5 plus this caused the early shift
[04:41] from Clos models to open model and more
[04:43] importantly it was without the Llama
[04:45] license restriction that many Enterprise
[04:47] lawyers were rather uncomfortable about
[04:49] as such one of the side effect was they
[04:51] became the default model for lots of
[04:53] cloud platforms including AWS gcp Etc
[04:56] with hundreds of fine tuning tutorials
[04:59] and the models was pushed heavily in
[05:01] replacing existing users GPD 3.5 work
[05:03] load for the respective Cloud
[05:05] providers resulting into lots of
[05:07] production environments today running on
[05:09] these models despite being it outdated
[05:13] by today's a standards one thing many
[05:15] people Miss is that for many commercial
[05:18] and enterpris SKS once they get
[05:20] something working reliably at scale
[05:22] especially once they have the metrics in
[05:24] place to observe changes and their
[05:26] reliability and they have prompted it to
[05:28] 99 % plus accuracy they really do not
[05:32] want to change their system and have it
[05:34] break overnight sure they can get an AI
[05:37] engineer to update the system
[05:38] instruction prompt every few weeks when
[05:39] a model updates or they can use a stable
[05:42] model version in open source and here's
[05:44] the crazy thing not change the
[05:47] model because if it end broke don't fix
[05:50] it so another Stand Out literally is the
[05:53] Lama 2 Lama guard model Lama 2 is up
[05:56] about 2% of our workload despite having
[05:59] new newer better versions of this model
[06:01] for basically everything in in this
[06:03] model class it's still the go-to model
[06:06] for AI Safeguard tutorials online
[06:08] because it it has haven't been updated
[06:10] and it's being actively used in
[06:12] production even for new teams that come
[06:14] online so that bring us to the
[06:17] topic what do people use open models
[06:20] for you see despite us being privacy
[06:23] friendly as a platform we strict no tax
[06:25] logging as a policy we can infer usage
[06:28] from the model uh being used and the
[06:30] metadata for the requesting application
[06:32] like what else we use Lama card for
[06:34] other than safe cards more importantly
[06:37] we can straight up ask our customers and
[06:39] exchange notes with agre like open
[06:41] routers which we did and here's what we
[06:43] see AI usage today sorted approximately
[06:47] by volume and usage AI for creativity or
[06:51] friendship AI for code AI for comy UI AI
[06:56] for write and check GPD very classic AI
[06:59] for agent and work that is not in the
[07:03] previous
[07:05] categories all of this is based on data
[07:07] that uh used by our customers directly
[07:09] as individual or as business for
[07:11] internal usage skill which in some cases
[07:14] could just mean that it's repackaging
[07:15] our API as an app for the App
[07:18] Store or AI web apps or agents that you
[07:21] play with
[07:22] online so getting back to it creative
[07:26] writing AI role playay and contship and
[07:29] too much smaller extent therapy in
[07:32] generally this use case represent the
[07:35] vast majority of noncoding AI requests
[07:38] represent 30 to 40% of all AI traffic at
[07:41] any point of time for creative writing
[07:44] it's apps like norval crafter a tool
[07:46] designed specifically to outline manage
[07:48] and draft your novel from the series law
[07:50] the high level navigation and
[07:52] collaborative writing on the text with
[07:53] other humans and AI this segment
[07:56] obviously is particularly popular with
[07:58] authors and with the fanfiction
[08:00] committee a small adjacent segment to
[08:02] this committee are folks who use AI for
[08:04] Creative content in games in particular
[08:06] Dungeons and dragon style kind of
[08:10] content for the other for the other
[08:12] group AI role playing companionship we
[08:14] have apps like Wy chat s Haven and a
[08:18] whole lots of them while there's a lot
[08:20] of social stigma around this segment due
[08:22] to its association with explicit or
[08:24] sexual content it is still the number
[08:27] one use case for AI today for non quote
[08:29] or agent take workf flows and the and
[08:31] it's the use case with the most number
[08:33] of active users be it directly or
[08:36] through the app store which uses our API
[08:38] under the hood it is also why Sam Alman
[08:41] and G can't stop teasing about the movie
[08:43] her because it's still a large percent
[08:46] of Cl Source AI movie uh
[08:49] usage also it's 2025 let's get the
[08:52] gender stereotype out of here cuz unlike
[08:55] popular belief it's not about you males
[08:58] over 60% of the users in this segment
[09:00] are women this mirrors a well known
[09:04] pattern where romance novels targeting
[09:06] women is the number one sales of books
[09:09] by volume by a really huge margin
[09:13] however you would't see a book stop or
[09:15] presenting themselves that way due to
[09:16] the social stigma and stereotype around
[09:18] it at least for most book
[09:20] stores likewise the same here is
[09:22] happening for
[09:24] AI so to fur Fight The
[09:26] Stereotype that all this is about R
[09:28] rated mil content let me quote one of
[09:30] the app makers
[09:31] here women tend to use these apps to
[09:34] hold long conversations and distress
[09:36] talking about their day-to-day lives uh
[09:39] every day in part because their real
[09:42] life partners are either non-existent or
[09:45] emotionally unavailable for them so ouch
[09:49] if you worried about AI stealing your
[09:50] partner learn to talk to her and be
[09:53] emotionally
[09:54] available which ties in to another usage
[09:57] Str that we see therapy and
[10:00] Jing there are lots of dedicated
[10:03] commercial apps on the App Store but
[10:05] when we ask users what apps they use is
[10:09] heavily fragmented it seems be it before
[10:12] or after AI silicon value can help but
[10:14] create another journaling app every
[10:16] single month one thing to note
[10:19] separately a good percentage of users in
[10:22] in our group that we we survey just
[10:24] essentially said that they use check gbt
[10:26] clones or their companion apps with a
[10:29] ter therapy character for the same use
[10:31] case essentially not being dependent on
[10:34] a specific therapy or
[10:37] journaling taking a few steps right into
[10:40] this broader category there's a reason
[10:43] why I group all these use cases all
[10:45] together in general this segment for
[10:48] this segment no one cares about MML this
[10:52] segment is all about Vibes Vibes Vibes
[10:55] and is the use case for a large s of
[10:57] various Community fine tun various
[10:59] different names and it's extremely
[11:01] competitive with top models ranking
[11:03] constantly changing weekly so what do I
[11:06] mean by Vibes for one it's ironically
[11:09] doing the one thing that is the complete
[11:11] opposite for every AI model instruction
[11:14] tune it is not rushing to answer the
[11:16] question or even solve or answer the
[11:19] question for example in therapy
[11:21] engineering the job of the therapist or
[11:23] in this case the AI is to guide and
[11:25] Empower a client to do what they want to
[11:27] reach their goal not tell you what to do
[11:30] the answer has to come from the
[11:32] individual likewise in story writing
[11:35] role play and companionship the term
[11:36] used is Slow Burn no one is watching
[11:40] Game of Thrones by starting from episode
[11:42] one and skipping everything by jumping
[11:44] in the last episode we came here for the
[11:46] entertainment in between not to talk
[11:48] about the ending at the dinner
[11:50] table so well there's a new exciting
[11:52] flavor for the community every few days
[11:55] just like there are new books every one
[11:58] of these models are unique and different
[12:01] one the model that can go howy and all
[12:03] cowboy that is the legendary alind
[12:05] magnum model one a model that
[12:08] specifically focused on science fiction
[12:10] something which apparently a lot of
[12:11] models are really bad at use the Rosa
[12:14] model given the speed this community
[12:17] moves the models I name will probably be
[12:19] replaced by next month
[12:21] frankly but when talking to the
[12:23] committee in this space where everyone
[12:26] plays and hops around model dieses
[12:29] focusing on the hot new celebrity tune
[12:32] for the week they sometime return to
[12:34] their old favorite as one user put it
[12:36] it's like playing a retro game from the
[12:37] memories he has his
[12:40] charms and I will emphasize that this is
[12:43] a category that has the largest skill
[12:46] for a sense of skill the current size of
[12:48] this user base and Community including
[12:50] close close Source commercial apps like
[12:52] character. is in the tens of millions
[12:55] everyone else is not even it's not even
[12:58] in the millions yet
[13:00] so the next major segment is coding
[13:05] co-pilot and coding
[13:07] agents which is about 20 to 30% of all
[13:12] traffic in general there are two
[13:14] segments to this group Auto completion
[13:18] tools similar to the original GitHub
[13:20] co-pilot or editing VI chat it which is
[13:23] basically available natively or through
[13:25] plin to every ID today you probably not
[13:28] even considering an ID anymore if you
[13:30] don't have these features as an
[13:33] option these features are now being
[13:36] served by dozens of AI model that are
[13:38] small and arguably good enough with
[13:40] parameter size ranging from 3 billion to
[13:42] 12 billion from reply M anly every AI
[13:44] lab Under the Sun I would argue Auto
[13:47] completion for code for this part is
[13:49] essentially solved so the Battleground
[13:51] for AI and code has moved to more
[13:53] agented code uh agents and I don't just
[13:57] mean this swe agent or dein style agent
[14:01] which is apparently too autonomous and
[14:03] goes into too many infinite Loops for
[14:05] many
[14:07] developers I mean nearly autonomous
[14:10] agent with lots of clarifying questions
[14:12] but involve interventions with humans in
[14:14] the loop kind of agent where humans can
[14:17] rapidly step in and make a tweet or
[14:18] suggest changes in chat whenever
[14:20] something goes slightly wrong the
[14:23] trending term for this phenomenon is
[14:25] called Vibe coding where basically you
[14:27] never touch the code and just keep
[14:29] chatting and prompting all your
[14:31] changes also because of how token hungry
[14:34] these agents can be one thing is known
[14:35] is how much traffic it ask for compared
[14:37] to the users of the previous segment a
[14:40] developer fully in the flow of VIP
[14:42] coding could essentially generate a
[14:44] thousand times more input and output
[14:45] tokens traffic back and forth than a
[14:48] single person chatting to a companion
[14:50] model so where there are at most tens of
[14:54] thousands coders that using these models
[14:57] at any point of time this traffic volume
[14:58] is growing ridiculously fast in the past
[15:02] week one side note to be clear on Cross
[15:06] referencing data from open router right
[15:08] now the vast majority of traffic is
[15:11] dominated by CL Sonet for this use
[15:15] case and we are not talking about a a
[15:18] small difference we're talking about
[15:19] over a 10 to1 ratio here most tools that
[15:22] support this more atic coding workflow
[15:24] like cursor is still integrate heavily
[15:27] towards the more commercial models
[15:30] however because of the volume of Ru cage
[15:32] and since the R1 wave we have seen a
[15:35] rapid growth in using such tools with
[15:37] open models this is part of the reason
[15:39] why there is no use for me presenting
[15:41] generary data because this coding
[15:43] segment itself went from basically under
[15:46] the 5% threshold in volume to easily now
[15:49] 20 30% of all
[15:52] traffic the one major open source
[15:54] project that sticks out that I would
[15:56] like to highlight is
[15:57] client which focuses on the chat agentic
[16:00] flow and when you combine it with the
[16:02] other open source project continue there
[16:04] for the auto completion integration you
[16:07] basically have the same level of
[16:09] experience as clot or open a models with
[16:12] cursor or any other uh ID platforms with
[16:15] agentic workflow fire R1 or we possibly
[16:18] using your own private Mech Studio
[16:20] cluster under the basement extremely
[16:23] popular for like all these hobby users
[16:25] who actually want to do this completely
[16:27] without the internet
[16:29] highly recommended that you uh give this
[16:31] open projects a try in vs code before
[16:33] they get f a dozen times in the next
[16:36] YC next up is confy UI and friends about
[16:40] 5% of the traffic for personal agentic
[16:42] workflows well many of you may be
[16:44] familiar with these two being widely
[16:46] used in the diffusion space for more
[16:48] complicated AI Generation image
[16:50] generation
[16:52] workflows similar uh graph style based
[16:55] uis are now B used right from reporters
[16:58] lawyers music Ians influencers and even
[17:00] po
[17:02] somehow where where these people are
[17:03] chaining complicated workflows to
[17:05] generate the tax that they want for
[17:06] their use
[17:08] case similar to coding agentic workflow
[17:11] the token explosion from a handful of
[17:13] this power user slowly stack up to
[17:15] noticeable
[17:16] levels but these users are not
[17:18] developers they are literally like I say
[17:21] musicians or like all these cretive
[17:23] personnels who learn how to use these
[17:26] tools however unlike client which saw a
[17:29] sudden explosion due to R1 the past few
[17:32] weeks this has been more about a slow
[17:35] and gradual user base build up in the
[17:38] past
[17:39] months it's also a space like most
[17:42] agentic platforms uh where it is
[17:44] essentially what I call a framework War
[17:46] if for those who are familiar with the
[17:47] JavaScript
[17:50] era the next major segment R and LGBT
[17:54] clones essentially about 20% of all
[17:56] requests at this point what every
[17:59] platform be fedus or open router or
[18:02] every other API provider will have their
[18:04] own internal check GPD UI our is called
[18:06] Phoenix a stand up application in this
[18:09] category that I would like to name is
[18:10] typing mine and in the application which
[18:14] surprise surprise builds you with a
[18:16] one-time fee instead of a subscription
[18:19] and can be used locally on your laptop
[18:20] against any API provider Like
[18:23] Us in particular is the level of UI
[18:26] polish and how they've been keeping Pace
[18:28] with cloning every single chat GPT UI
[18:30] feature into their app and customizing
[18:33] that with even their own plugin system
[18:35] beyond that you probably heard this use
[18:37] case a thousand time ch gbt right y so
[18:40] let's skip to the one that everyone
[18:42] wants to hear more about AI for agents
[18:44] and work representing 10 to 20% of all
[18:47] our traffic because agent is such an
[18:51] over abused term today I'll split this
[18:54] into two major categories to make things
[18:57] clear workflow automation on Arrow
[18:59] agents and fully automated
[19:03] agents if I uh so right now let's start
[19:05] from workflow automation on Arrow agent
[19:07] for most of you who's working on agents
[19:10] in Enterprises your number one priority
[19:13] now is to get all your agents into
[19:17] production by maximizing Roi for your
[19:20] company and shareholder value if like
[19:22] use item without limiting the negative
[19:25] impact especially since we are in New
[19:27] York lots of financial institutes are
[19:29] risk averse by default with many of you
[19:32] potentially working in developing your
[19:34] agents right now so have that stands
[19:37] buil in human Escape hatches by
[19:40] default what I mean by that is basically
[19:43] if you're building an automation system
[19:45] in your
[19:45] company like way more make it so that
[19:48] the human can take the driver seat
[19:50] needed from day
[19:52] one so for example we work with a few
[19:55] Insurance claim companies and logistic
[19:57] companies advising them on how to fully
[19:58] and automate their email process which
[20:00] is the part of their
[20:02] work a common pattern we advise them
[20:04] would be them to create an AI agent and
[20:07] UI for fully automating drafting
[20:09] responses for inbound emails checking
[20:12] against inventories checking against
[20:13] rules checking a lot other things in the
[20:15] process and build a platform you have
[20:17] for editing and finalizing and sending a
[20:20] response in best case scenario if the AI
[20:22] did everything perfectly it's just all
[20:24] about clicking send and sometimes these
[20:26] things are built on top their existing
[20:28] customers
[20:29] Salesforce or Erp
[20:32] system however more importantly it at
[20:35] least have one human checking the final
[20:37] submissions before it hits the the end
[20:39] user when done right at launch the AI is
[20:42] able to successfully drop around 80 to
[20:44] 90% of the response with humans
[20:46] rejecting emly taking over the remainder
[20:48] so there's no harm to everyone else
[20:51] productivity for the responders shoots
[20:53] through the roof management is Happy the
[20:55] AI is
[20:57] adopted and if any any mistakes were
[20:59] made and the human field to correct it
[21:02] well that's kind of the human spot not
[21:03] the
[21:04] AI over time as confidence start to
[21:07] build they then start to add
[21:08] classification for certain known
[21:10] reliable use case and eventually start
[21:13] fully automating those use
[21:15] cases it's like auto reply to certain
[21:18] certain
[21:20] scenarios with full confidence after
[21:22] having seen the system run for thousand
[21:24] of
[21:25] customers on the flip side teams that
[21:28] went full fully ambitious into full 100%
[21:32] automation without human Escape
[21:34] Hedges sometimes they start with a
[21:36] successful launch because everyone
[21:38] wanted it to suce but more company as
[21:41] they run the system and as more users
[21:44] use it they eventually get fully burned
[21:46] by an angry customer for a really bad
[21:48] automated response down the line in some
[21:51] cases this may be fully acceptable
[21:53] compromise that management accepts from
[21:54] the start because the savings benefit is
[21:57] worth it
[21:59] other times this kills the entire AI
[22:01] project essentially postponing AI
[22:03] adoption in your organization for
[22:05] another year a scenario that you do not
[22:07] want to
[22:11] happen and this is commonly because
[22:14] these a lot of teams end up developing
[22:17] an entire fully automated workflow
[22:21] without trying to mooving into
[22:23] production early that's why I say your
[22:25] goal is to go beyond the PC phase and in
[22:28] to adoption in your company at scale in
[22:31] some portion as fast as possible and to
[22:34] inter uh integrate and iterate from
[22:37] there so that leaves the other mythical
[22:39] category where which everyone loves to
[22:41] chase fully truly 100% reliable agentic
[22:45] agents that is fully
[22:47] automated just don't it does not exist
[22:51] everyone has who has done it tried to D
[22:53] it has got
[22:55] burnt and it we are not
[22:58] and we are talking about things in
[23:00] production not
[23:03] PC the mindset that we should be
[23:05] thinking when we try to build AIS into
[23:08] production is that we should approach
[23:11] things of like trying to solve the 80%
[23:13] with Escape hatches along the
[23:17] way because at even at
[23:19] 80% for some of you Mega cops here
[23:23] that's already millions in productivity
[23:25] and
[23:26] saving furthermore do I need to remind
[23:29] you that even humans are not 100%
[23:32] reliable so only do this when the
[23:35] eventual mistake right is acceptable and
[23:38] can be
[23:39] fixed and it's a basically a trade off
[23:41] they willing to take so common example
[23:44] is co- calling systems when you're
[23:46] actually willing to lose a lead because
[23:49] you did you wouldn't have gotten
[23:50] otherwise anyway or sometimes customer
[23:54] support because you can get a human to
[23:56] apologize later
[23:58] but rewinding back is like you should
[24:00] take the approach just like how Google
[24:01] software reliability Engineers or any
[24:04] reliability engineering for industry
[24:06] where safety and reliability is
[24:07] Paramount
[24:08] do start with an extremely streamlined
[24:11] reliable system for your 80 to 90%
[24:14] scenarios and after you're done do it
[24:17] for another 80 to 90% for that 10 to 20%
[24:20] failure scenarios and repeat this
[24:22] process 10 times and now suddenly you
[24:25] have 99.998% reliability
[24:29] if if you're an airliner that's not
[24:30] boing do it another 10 times and
[24:32] everyone is happy with incremental gains
[24:34] and and improvements it may not be the
[24:37] sexy first launch it may not be the most
[24:40] wild to do it this way but at the r
[24:42] least your project survives to
[24:44] production you have huge impact to
[24:47] Roi and you can iterate from
[24:52] that and more importantly incrementally
[24:54] approved and amusingly properly never
[24:58] change some of the models that you use
[24:59] and forever give me business which I'm
[25:03] only going to do and say the following
[25:06] hey featherless customers especially the
[25:07] more enterprising ones please try to
[25:10] upgrade from Lama 2 to something newer
[25:11] this year or next if done right it's
[25:14] probably a free 99 to 99.9% Improvement
[25:17] I know all of you are using this model
[25:19] and came to us in part because we are
[25:20] one of the last few providers to host it
[25:22] and we forever will but hey I'm giving
[25:25] this advice it's free real
[25:27] estate similarly hey for closeup slabs
[25:32] it's
[25:33] 2025 you do not need AGI to learn how to
[25:36] use G version from AI
[25:38] models I say this is all seriousness
[25:41] because for companies in production who
[25:42] is trying to incrementally improve with
[25:44] each St to 99 plus 99999 per. it's
[25:48] nearly impossible to do so if you change
[25:50] the model every
[25:52] week so with that H shs I'm out of
[25:56] time all the best in building your AI
[26:00] agents Hey Hey Eugene come back here
[26:03] you're forgetting the one more thing bit
[26:05] ah crap he can't hear me the laptop
[26:08] speakers are muted and I have no control
[26:10] over that you see us AI may be flawed
[26:12] but honestly we are probably more
[26:14] consistent and reliable than humans are
[26:16] as you can clearly see uh oh well here
[26:20] goes me saving the day hi am quirky a 72
[26:23] billion parameter linear Transformer and
[26:25] a tension Transformer hybrid with a
[26:27] completely new architecture that runs at
[26:30] less than half the gpu's compute cost of
[26:33] other Transformer models the strongest
[26:35] post Transformer hybrid to date when
[26:37] Eugene proposed training a post
[26:39] Transformer model to provide an
[26:40] alternative to attention is all you need
[26:43] which runs at a fraction of the
[26:44] inference cost many of you said it can't
[26:47] be done the tech is unproven and will
[26:49] not scale well deep seek cost 10 million
[26:53] uh quirky cost only a 100,000 to build
[26:57] you can find out out more about our
[26:59] model at the following link more
[27:01] importantly as we enter the array where
[27:02] the average AI model has better MML then
[27:06] the average office worker The Benchmark
[27:09] has lost its meaning after all how many
[27:11] of you audience can calculate orbital
[27:13] re-entry from Earth to Mars or PhD math
[27:16] questions all of which are questions
[27:18] apparently Frontier AI models are now
[27:21] capable of how many of our AI agents
[27:24] today can be reliably be trusted with
[27:26] one task it's instructed to do so
[27:28] without hallucination or failure I think
[27:31] you get the point what we find more
[27:33] exciting is exploring a future where we
[27:35] take advantage of linear Transformer
[27:37] models as a means of persisting memories
[27:40] customization and improving reliability
[27:42] for future AI models to make useful AI
[27:46] agents and if you would like to run
[27:48] featherless or quirky in your private
[27:50] cloud or on premise environment reach
[27:52] out to us and we would like to hear more
[27:55] about your use case
