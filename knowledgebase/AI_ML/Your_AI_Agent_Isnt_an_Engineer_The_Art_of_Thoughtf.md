---
type: youtube
title: Your AI Agent Isn't an Engineer: The Art of Thoughtful Anthropomorphism
author: AI Engineer
video_id: MExbNNG_VcI
video_url: https://www.youtube.com/watch?v=MExbNNG_VcI
thumbnail_url: https://img.youtube.com/vi/MExbNNG_VcI/mqdefault.jpg
date_added: 2025-05-26
category: AI and Software Development
tags: ['AI marketing', 'developer experience', 'AI ethics', 'software engineering', 'tech trends', 'AI limitations', 'developer surveys', 'human-AI collaboration', 'tech industry', 'AI tools']
entities: ['chat GPT', 'GitHub Copilot', 'Stack Overflow', 'Wired', 'OpenAI', 'AI agents', 'software engineers', 'developers', '2024 Stack Overflow developer survey']
concepts: ['AI marketing', 'developer alienation', 'unrealistic expectations', 'AI limitations', 'workflow automation', 'human-AI collaboration', 'sensationalism in tech', 'authentic marketing', 'AI ethics']
content_structure: discussion/opinion
difficulty_level: intermediate
prerequisites: ['Basic knowledge of AI tools like chat GPT', 'Understanding of software development workflows', 'Familiarity with AI marketing trends']
related_topics: ['AI ethics', 'developer tools', 'AI in software engineering', 'marketing strategies', 'human-AI collaboration', 'AI limitations', 'developer surveys', 'tech industry trends']
authority_signals: ["'according to a 2024 Stack Overflow developer survey'", "'I have a PhD in AI I work to develop some of these algorithms'"]
confidence_score: 0.8
---

# Your AI Agent Isn't an Engineer: The Art of Thoughtful Anthropomorphism

**Video**: [Watch on YouTube](https://www.youtube.com/watch?v=MExbNNG_VcI)  
**Published**: 3 months ago  
**Category**: AI/ML  
**Tags**: ai, developer-relations, marketing, anthropomorphism, ai-ethics, software-engineering, developer-advocacy  

## Summary

# Summary of "Your AI Agent Isn't an Engineer: The Art of Thoughtful Anthropomorphism"

## Overview  
Roselle Scarlet, a developer advocate, critiques the practice of anthropomorphizing AI tools (e.g., marketing them as "engineers" or "friends") and highlights how this misleads users, alienates developers, and undermines trust. The talk emphasizes the need for authentic marketing that focuses on AI’s real value—automation and collaboration—rather than unrealistic expectations of human-like intelligence.

---

## Key Points  
- **Anthropomorphism in AI Marketing**:  
  - AI tools (e.g., Claude, ChatGPT) are often marketed with human-like traits (e.g., "thinking," "reasoning") to make them relatable.  
  - This creates the false impression that AI can independently think, reason, or replace human workers.  

- **Consequences of Misleading Marketing**:  
  - **Unrealistic Expectations**: Users expect AI to perform at human levels, but AI is non-sentient, context-sensitive, and prone to errors (e.g., hallucinations).  
  - **Alienating Developers**: 76% of developers use or plan to use AI, but framing it as a job threat undermines trust and collaboration.  
  - **Credibility Risks**: Misaligned expectations damage product credibility and developer relationships.  

- **Real Value of AI**:  
  - AI’s strength lies in automation, parallel task execution, and augmenting human work—not replacing it.  
  - Developers value tools that enhance productivity, not tools that promise to "steal" their jobs.  

- **Developer Sentiment**:  
  - A 2024 Stack Overflow survey shows 76% of developers use or plan to integrate AI.  
  - A Wired article highlights developer frustration: 30% of game developers express negative sentiment toward AI initiatives.  

---

## Key Quotes  
1. **"I have a PhD in AI... I feel a deep regret for how naively I offered up my contributions."**  
2. **"We should use generative AI to help people be faster at their jobs, not lose them."**  
3. **"AI is non-sentient... it sometimes hallucinates... these are just some of the limitations."**  

---

## Actionable Takeaways  
1. **Avoid Human-Like Descriptions**: Refrain from marketing AI as "thinking" or "reasoning" to prevent unrealistic expectations.  
2. **Highlight Real Value**: Emphasize automation, parallel processing, and collaboration over human-like capabilities.  
3. **Set Realistic Expectations**: Clearly communicate AI’s limitations (e.g., context sensitivity, non-deterministic outputs).  
4. **Prioritize Authenticity**: Use transparent marketing that aligns with developer needs, avoiding hyperbolic claims.  
5. **Engage Developers as Partners**: Frame AI as a tool to enhance workflows, not replace human expertise.  

--- 

This summary underscores the importance of ethical, transparent AI marketing to build trust and foster meaningful collaboration between developers and AI tools.

## Full Transcript

[00:00] hey everyone today I'm going to talk to
[00:01] you about why you should stop referring
[00:03] to your AI agent as a software engineer
[00:06] and the Art of thoughtful
[00:08] anthropomorphism now these are a lot of
[00:10] convoluted terms but really what I'm
[00:12] just trying to say is how to do better
[00:14] developer marketing and developer
[00:16] relations for your AI agent and other AI
[00:20] related tools my name is Roselle scarlet
[00:22] and I am a staff developer Advocate at
[00:24] blog where I focus on all things open
[00:27] source and all things AI prior to this I
[00:29] work at GitHub basically doing the same
[00:31] thing but for GitHub co-pilot now I want
[00:34] to know about you as well I know we're
[00:36] virtual but please interact with me
[00:39] raise your hand if you've ever been
[00:41] personally victimized by the question
[00:43] will AI replace software Engineers H
[00:46] it's such an eye roll or it can trigger
[00:48] different responses you might have the
[00:50] people that are rolling their eyes and
[00:51] they're like I know Cobalt and I'm going
[00:54] to stick to Cobalt I'm not learning
[00:56] anything AI I do not care and then you
[00:58] have the people that are like panicking
[01:00] they like oh my gosh oh my gosh oh my
[01:02] gosh I need to learn AI I need to do all
[01:04] the AI courses I need to sign up for all
[01:07] the AI jobs I don't want to be left
[01:09] behind now it does seem like a
[01:11] hypothetical or frivolous concern but
[01:15] companies are making hiring decisions
[01:17] based on AI productivity for example
[01:19] salesforce's CEO recently announced
[01:21] plans to reduce hiring software
[01:24] engineers and support Engineers because
[01:26] he saw a 30% boost in productivity from
[01:29] from Ai and now let me tell you guys my
[01:33] response as a developer advocate in AI
[01:36] my response has always been upskill and
[01:38] adapt to the changing economy after all
[01:40] you don't want to be that person that is
[01:42] still driving a horse and buggy when
[01:44] everybody's moved on to a car and I
[01:48] genuinely do believe AI is a helpful
[01:50] tool I've used it to help me understand
[01:52] new technologies and quickly prototype
[01:55] ideas however on the inside I wrestled
[01:59] with this question why do we keep
[02:01] framing AI as a replacement for
[02:03] developers and human beings so we're
[02:06] going to kind of dig into that we're
[02:07] going to talk about my spicy take a
[02:09] little bit we're going to talk about
[02:11] anthropomorphism what it is how it's
[02:13] affecting our industry why it's a
[02:15] problem and we'll talk about a framework
[02:18] to do some
[02:19] authentic AI marketing or developer
[02:23] marketing and how to really appeal to
[02:25] developers in a way that still builds
[02:27] trust but doesn't compromise your
[02:29] integrity
[02:31] so let's talk about my spicy take right
[02:34] AI replacing software Engineers where in
[02:36] the world this narrative come from I
[02:39] think we our industry we developers and
[02:43] marketers and developer relations folks
[02:45] we help to shape this narrative
[02:47] unfortunately I think we were like kind
[02:49] of leaning into to a lazy marketing
[02:52] strategy that prioritized quick WIS over
[02:54] sustainable adoption basically we wanted
[02:57] to tell VCS and execu buy our product
[03:01] but it's much harder to tell them to buy
[03:03] our product when they are already paying
[03:07] Engineers $300,000 400 500 and now we're
[03:11] like buy them this extra toy they're
[03:14] like absolutely not but we're like oh
[03:17] you know what actually you can get rid
[03:20] of some of those engineers in place of
[03:23] my tool my tool will help you to cut
[03:25] those costs increase productivity and I
[03:27] know that's what you're all about and
[03:29] that's where we start leaning into
[03:31] anthropomorphism now many of you might
[03:33] be like anthropomor what all right
[03:36] anthro meaning relating to humans really
[03:39] just means assigning human traits to
[03:40] non-human entities and it's really not
[03:44] inherently problematic or bad in fact
[03:47] it's a really common practice and it
[03:49] makes digital experiences more familiar
[03:51] more intuitive it gives us like that
[03:53] psychological emotional connection to a
[03:56] digital tool for example we have ebooks
[04:00] some some eBooks have like page turning
[04:02] animations and Page turning sounds even
[04:05] though there's no paper there's no
[04:07] actual pages and then electric cars have
[04:10] pre-recorded engine
[04:12] sounds and this is something that Su P
[04:15] talked with me about briefly on Blue Sky
[04:18] where he kind of just pointed out that
[04:20] electric
[04:21] engine case to me when I was complaining
[04:24] about AI tools Being Framed as humans
[04:27] he's like this is going to happen it's
[04:28] very similar to how electric cars have
[04:31] these pre-recorded engines even though
[04:33] they don't have a combustion engine it's
[04:35] just to make the the driver the user
[04:38] feel familiar feel connected and be like
[04:41] okay I think I know how to use this
[04:42] there's like a familiar affordance to
[04:44] operating the tool but AI is kind of
[04:47] different because for a long time it's
[04:49] been so based in Academia and only for
[04:52] the the PHD folks who have a who had a
[04:55] dissertation and all this big stuff so
[04:59] when there's this complexity and
[05:01] blackbox nature it's harder to grasp
[05:04] some of the capabilities and limitations
[05:06] so what we decided to do is like oh you
[05:08] know what let me just give it some
[05:10] humanlike descriptions like we're saying
[05:13] Claude is a friend You've Got a Friend
[05:14] in Claude this is a a a sign or
[05:18] advertisement that was at the airport or
[05:20] when Devon was first introduced it was
[05:22] introduced as an AI software engineer
[05:25] and when you use chat GPT sometimes you
[05:27] get a little signal instead of it saying
[05:29] look voting it says oh Chad GPT is
[05:31] thinking it's
[05:33] reasoning okay and you're probably like
[05:35] so what's the problem we're making it
[05:37] familiar for folks what's wrong with
[05:40] that and I think it's self-sabotage
[05:43] because it's misleading users to believe
[05:45] that AI can think reason and work
[05:48] independently like humans because of
[05:51] that we're alienating developers we're
[05:53] setting these really high unrealistic
[05:55] expectations of our tools and we're
[05:57] missing the real value proposition
[05:59] position of AI agents so let's dig into
[06:02] the idea about a alienating developers
[06:05] when AI is marketed as an engineer
[06:08] decision makers view it as a onetoone
[06:10] substitute for human talent and this is
[06:13] counterproductive because developers are
[06:15] AI power users in fact according to a
[06:18] 2024 stack Overflow developer survey 76%
[06:22] of the developers said that they either
[06:26] currently use AI or they plan to
[06:28] integrate it into their workflows so why
[06:31] would you have these people who are
[06:34] excited about and wanting to use the
[06:36] product and then on the flip side you're
[06:38] telling them it's going to take your job
[06:40] use it more and it'll get better and
[06:43] then eventually it'll steal your job
[06:45] that doesn't make sense and don't take
[06:47] my word for it I found this article by
[06:50] wired called game developers are getting
[06:51] fed up with their boss's AI initiatives
[06:54] and in it they pointed out that 52% of
[06:57] companies have now adopted generative AI
[06:59] in their games but 30% of the survey
[07:01] developers expressed negative sentiment
[07:04] and then there was these two quotes that
[07:06] really stood out to me one was someone
[07:09] said I have a PhD in AI I work to
[07:11] develop some of these algorithms used by
[07:13] generative AI but I feel a deep regret
[07:17] for how naively I offered up my
[07:20] contributions like dang and another
[07:22] person said we should use generative AI
[07:25] to help people be faster at their jobs
[07:27] not lose them that's my point as well
[07:30] and on top of that it creates these
[07:32] unrealistic expectations right if AI is
[07:35] marketed as working just like human as
[07:38] mid-level software engineer users expect
[07:41] it to perform at human levels but the
[07:43] reality is AI is nons sentient it's
[07:46] trained on historical data patterns it
[07:49] sometimes misses context it sometimes
[07:52] hallucinates it sometimes has
[07:53] non-deterministic output these are just
[07:55] some of the limitations not throwing
[07:58] shade at AI this is sometimes what
[08:00] happens in reality and then developers
[08:02] get upset or irritated they're like
[08:05] that's not what you marketed it as you
[08:06] said it was perfect you said it was
[08:08] probably even better than me so now your
[08:11] company risk losing credibility and so
[08:14] does your product because developers are
[08:16] really focused on authenticity they
[08:20] really want authentic marketing they
[08:21] don't want you to say this is the
[08:22] biggest bestest most performant tool if
[08:26] it's not right here's the the thing
[08:30] about like setting all these unrealistic
[08:32] expectations we're actually missing the
[08:34] real value here right the value of AI
[08:37] agen is so you can work in parallel
[08:39] where it's automating borrowing tasks
[08:41] for you it's F doing faster prototyping
[08:43] or allowing you to it's allowing you to
[08:45] do quicker debugging that way you can do
[08:47] more creative problem solving and make
[08:50] um more high impact um contributions to
[08:54] your company and I think it's going to
[08:56] get a little bit worse because we're
[08:59] entering these years of the agent right
[09:02] some people are dubbing 2024 and 2025
[09:05] the as the year of the agents and for
[09:07] folks who might not know what a AI agent
[09:10] is people are describing it kind of like
[09:12] a a butler an assistant it does things
[09:15] for you again anthropomorphism here
[09:17] right it can execute shell commands
[09:19] maybe some of them can create calendar
[09:21] events for you some of them can just
[09:23] build hold applications and because of
[09:26] its Behavior it makes anthropomorphic
[09:28] marketing a little bit harder to avoid
[09:31] but we've seen the effect that it can
[09:33] have so how do we stand out and get
[09:36] adoption of our tool but still build
[09:39] trust with developers I've come up with
[09:41] this framework that has worked for me
[09:44] with many AI tools so this is my
[09:46] framework for thoughtful
[09:48] anthropomorphism because at the end of
[09:50] the day we need a little bit of it but
[09:52] we can do it in a uh more authentic way
[09:55] right first off we need to understand
[09:57] how it works we need to thoughtfully
[10:00] name our tools we need to focus on
[10:03] augmentation over replacement we need to
[10:05] be transparent we need to emphasize
[10:08] developer control show don't tell
[10:11] encourage good documentation clear
[10:14] documentation and also Foster open
[10:17] collaboration so let's dive into each of
[10:19] these very quickly when I say understand
[10:22] how it works I know you're not the
[10:24] engineer that built it you're probably
[10:27] the developer relations so social media
[10:29] marketer Communications an executive
[10:32] somebody that's a salesperson somebody
[10:34] that's trying to get people to adopt the
[10:37] product and be aware of it so you don't
[10:39] really know exactly how everything works
[10:42] but it's your responsibility to learn in
[10:45] my opinion right become customer zero
[10:48] before that tool goes out to the public
[10:50] use the product so much even when it's
[10:53] out to the P public keep experimenting
[10:55] with it because they're going to keep
[10:56] adding new features to the product and
[10:58] inv time into learning the fundamentals
[11:01] of AI understand like what llms are and
[11:05] their capabilities the differences
[11:06] between co- pilots and agents understand
[11:09] core AI agent operations how tokens work
[11:13] how context management works so that
[11:15] it's easier to help troubleshoot
[11:17] people's errors tool calling understand
[11:19] what that is and all of the limitations
[11:22] that come with a AI agent and understand
[11:25] the agentic loop many agents have
[11:27] different agentic Loops there's like
[11:29] some um specific recipes for them but
[11:32] here's an example of one agentic Loop
[11:34] right and this is one I'm most familiar
[11:36] with where a user makes a request so
[11:39] let's pretend me I'm the user and I'm
[11:41] like hey AI agent I want you to generate
[11:44] some test for my web application and
[11:46] then my AI agent says oh relle wants to
[11:49] generate test so it goes to my llm which
[11:52] could be uh Claude Sonet 3.5 or it could
[11:56] be GPT 40 or whatever and it's like oh
[11:59] my gosh rzo wants to generate test and
[12:01] here's the tools that I have help me out
[12:03] the llm comes up with a plan they're
[12:05] like use the generate test tool maybe
[12:07] Cypress or playright and you know what
[12:10] you need to do you need to create this
[12:11] folder create these files import these
[12:14] dependencies and start creating a test
[12:17] suite and then it the agent says yes sir
[12:20] I can do it it executes those plans and
[12:23] Tool calls and then it goes back to the
[12:25] llm and it's like does this look right
[12:27] if it looks right it goes and delivers
[12:29] the results to me relle and if it
[12:32] doesn't look right the llm and the agent
[12:35] go back and revise the plan again and it
[12:37] waits for the next request from me so
[12:40] here's me playing with an AI agent just
[12:42] so you can get an idea of how it works
[12:45] this is code name Goose that my company
[12:47] made I actually played tic tactoe with
[12:50] it so what happens is I say I played it
[12:53] takes in that information brings it to
[12:54] the llm the llm Tells it to take a
[12:56] screenshot and decide on where it's
[12:58] going to play and how it's going to play
[13:00] so it takes a screenshot with the screen
[13:02] capture tool that it has and it decides
[13:04] okay I'm going to use HTML and I'm going
[13:06] to make my move um right here so it
[13:09] takes a bit because it's communicating
[13:12] with the llm at the moment so we'll see
[13:14] that
[13:15] happen
[13:16] [Music]
[13:18] and there it goes it put a o now ai
[13:21] again it's not that smart I ended up
[13:24] winning um so that you can see like it's
[13:26] not all perfect there were moments when
[13:28] we were watch watching this where it was
[13:30] struggling it was like oh I it wasn't
[13:32] able to get the screen capture and it
[13:33] had to try again and revise its plan on
[13:36] how it was going to do that so let's
[13:38] talk about thoughtful naming as well we
[13:41] wanna at least for me right I say use
[13:45] anthropomorphism sparingly only when
[13:47] needed try to choose nonhuman names and
[13:50] avoid titles like AI Engineers because
[13:52] that's really going to throw some
[13:53] developers off where they're like this
[13:55] isn't acting like an a real engineer
[13:56] it's making mistakes even though
[13:58] engineers make mistakes I prefer if you
[14:01] use like clear terms like co-pilot agent
[14:04] assistant I really think get help
[14:07] co-pilot even though this is not an
[14:09] agent and now it's moving into an
[14:10] agentic mode they really went off when
[14:13] they pioneered the term co-pilot they
[14:16] really really did because they thought
[14:18] about the fact that hey it's not doing
[14:20] the work for you it's helping you do the
[14:23] work you're the the the person
[14:25] controlling it and so like co-pilot I
[14:28] thought was a really appropriate term
[14:30] that everyone else has picked up and
[14:32] then we want to talk about focusing on
[14:35] augmentation over replacement I wrote
[14:38] this blog post called the average
[14:40] developer is a multitasker and here's
[14:43] the thing an agent helps you to work in
[14:45] parallel because Modern Day Developers
[14:47] we have multiple roles we're parents
[14:49] we're maintainers we're instructors on
[14:50] the side and we should be instead of
[14:53] saying oh this is completely going to
[14:54] replace the developer it's going to
[14:56] complement their responsibilities and be
[14:58] part of a developer toolkit next we want
[15:01] to talk about
[15:04] transparency oh my gosh I think this is
[15:06] so important I'll tell you a story why
[15:09] first off I think you should consider
[15:10] open source when possible if not try to
[15:13] publish white papers and go to
[15:15] conferences and talk about how it works
[15:17] because this prevents misinformation
[15:20] spreading okay let me tell y'all the
[15:22] story when get help co-pilot have first
[15:25] gone from like beta to public there
[15:27] would be a lot of Twitter space of
[15:29] people discussing and trying to theorize
[15:31] how does this thing work and I would be
[15:33] listening but I wasn't on the stage so I
[15:35] couldn't talk and explain and it wasn't
[15:37] public information yet on how it worked
[15:39] so I was like I don't even know if I can
[15:41] get up there and say it right so people
[15:43] would be like here's what's happening as
[15:45] you type it goes out searches through
[15:48] repos steals code comes back and gives
[15:51] the code and I'm like that's that's not
[15:53] how it works so it's really good to get
[15:56] ahead of the narrative before people
[15:58] create The Narrative for you the next
[16:01] thing I want to talk about is developer
[16:03] control this is really powerful because
[16:05] it helps to build trust with developers
[16:07] give them the ability to customize the
[16:09] choice of their llm customize the
[16:11] behavior is it going to be verbos like
[16:13] the agent going to be verbos is it going
[16:16] to be more concise allow them to see
[16:18] debugging logs and allow them to
[16:20] integrate it into their workflow through
[16:22] like connecting it to different apis and
[16:24] stuff like that again I do think code
[16:27] name goose is good at this and I I'll
[16:29] point out different tools that I think
[16:31] are good at things right Cod name Goose
[16:33] just is good at this because one it's
[16:35] open source two it connects to model
[16:38] context protocol servers and we use
[16:41] those as extension so you can connect it
[16:42] to like figma or jet brains or whatever
[16:45] and I think that's cool now another
[16:48] thing I think is really important and a
[16:50] lot of companies Miss is showing and not
[16:52] just telling a lot of times uh companies
[16:54] overpromise and you're like this agent
[16:56] can do everything for you and you're
[16:58] like what what everything can it do and
[17:00] I haven't seen it happening and I don't
[17:02] know how to make it work so use short
[17:04] videos gifs blogs to demo helpful things
[17:07] like test Suite creation converting code
[17:11] from one language to another
[17:12] transforming wireframes into like uis or
[17:17] generating comments into different docs
[17:19] um and this is scary but go for the live
[17:23] demos these are good teaching moments I
[17:26] know AI doesn't always come out right
[17:28] but it also allows the audience to see
[17:30] oh shoot is this how this person
[17:33] troubleshoots things when it's not
[17:34] working and they don't like to see like
[17:36] the Polish demos all the time sometimes
[17:38] you want to do like a little magic trick
[17:40] but sometimes it's cool to be like oh
[17:42] they're struggling with this part I've
[17:44] struggled with that part how do I
[17:45] navigate this so what I used to do a lot
[17:48] for GitHub co-pilot that worked is I
[17:50] would do a simple demo where GitHub
[17:52] copilot will help me to connect to
[17:54] Twitter's API and post I wrote this
[17:56] tweet with co-pilot and I'm at XY
[17:59] conference now this was fun and
[18:02] memorable for people people that were
[18:04] there would get excited they would be
[18:06] amping me up when Coop pilot wasn't
[18:08] generating the right thing and then all
[18:09] of a sudden when it did they're like yay
[18:11] and then people that weren't at the
[18:13] conference would get a little bit of
[18:14] foone w they' be like how did brazelle
[18:16] write something with co-pilot like how
[18:18] did she write a tweet with co-pilot we
[18:20] want to know even one person from react
[18:23] Miami got it
[18:25] framed the the conference organizer so
[18:28] you want something that people are
[18:29] remembering and making like feeling
[18:31] excited about documentation I think this
[18:35] one is a straightforward one where you
[18:36] want to have installation guides you
[18:38] want to have prompt playbooks you want
[18:40] to give people understanding of how the
[18:42] data is being used um so that they can
[18:44] feel more empowered to use your product
[18:47] and Foster an ecosystem of open
[18:50] collaboration right through GitHub
[18:52] discussions or Discord you want to um
[18:55] leverage this because it'll enable to
[18:59] have more knowledge sharing so you'll
[19:01] have people who are using the product
[19:03] and also kind of become developer
[19:05] advocates for you where they're like hey
[19:07] this prompt worked for me did it work
[19:09] for you and I think one company that
[19:12] well I know this is not by the company
[19:15] this is done by the community but it's
[19:17] so awesome that they've created this
[19:19] ecosystem where even the community just
[19:21] started this called cursor. directory I
[19:24] love the love cursor's ID they have the
[19:26] composer agent and cursor C do directory
[19:29] is basically a collection of prompts
[19:31] that people liked for cursor rules and
[19:33] have used and people can other people
[19:35] can just copy them and use them
[19:37] sometimes you just want to see what
[19:38] works for other people so you can
[19:40] replicate it as well so just to go over
[19:43] the framework again it's understanding
[19:45] how it works using thoughtful naming
[19:47] going for augmentation over replacement
[19:50] focusing on being transparent developer
[19:53] control showing not just telling do
[19:56] using documentation heavily and
[19:58] fostering an ecosystem that is focused
[20:01] on open collaboration now I'll leave you
[20:04] with just a few words saying how we
[20:07] present AI shapes how the world sees it
[20:09] so I would love for us to move Beyond
[20:11] The Narrative of AI agents replacing
[20:14] developers thank you and you can go
[20:17] ahead and follow me at black R bites bye
